{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc5841e-02cf-4a81-af7c-2121de0aa2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "627076eb-4e1c-4975-9bbe-888f8c971fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pub_agency_name</th>\n",
       "      <th>agency_type_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>division_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>region_name</th>\n",
       "      <th>population_group_code</th>\n",
       "      <th>offense_code</th>\n",
       "      <th>offender_race</th>\n",
       "      <th>offender_ethnicity</th>\n",
       "      <th>offender_age</th>\n",
       "      <th>offender_sex</th>\n",
       "      <th>victim_type_code</th>\n",
       "      <th>location_code</th>\n",
       "      <th>weapon_code</th>\n",
       "      <th>prop_desc_code</th>\n",
       "      <th>stolen_value</th>\n",
       "      <th>recovered_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Angelina</td>\n",
       "      <td>County</td>\n",
       "      <td>Texas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>ANGELINA</td>\n",
       "      <td>South</td>\n",
       "      <td>8B</td>\n",
       "      <td>26B</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>20</td>\n",
       "      <td>375.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122951</th>\n",
       "      <td>151487</td>\n",
       "      <td>Polk</td>\n",
       "      <td>County</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>POLK</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122952</th>\n",
       "      <td>151488</td>\n",
       "      <td>Polk</td>\n",
       "      <td>County</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>POLK</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>36</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122953</th>\n",
       "      <td>151489</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>County</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>240</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>78</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122954</th>\n",
       "      <td>151490</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>City</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>SHELBY</td>\n",
       "      <td>South</td>\n",
       "      <td>1B</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122955</th>\n",
       "      <td>151491</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>County</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>240</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122956 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 pub_agency_name agency_type_name      state_name  \\\n",
       "0                0        Angelina           County           Texas   \n",
       "1                1       Jefferson           County         Alabama   \n",
       "2                2       Jefferson           County         Alabama   \n",
       "3                3       Jefferson           County         Alabama   \n",
       "4                4       Jefferson           County         Alabama   \n",
       "...            ...             ...              ...             ...   \n",
       "122951      151487            Polk           County         Florida   \n",
       "122952      151488            Polk           County         Florida   \n",
       "122953      151489        Berkeley           County  South Carolina   \n",
       "122954      151490         Memphis             City       Tennessee   \n",
       "122955      151491        Berkeley           County  South Carolina   \n",
       "\n",
       "             division_name county_name region_name population_group_code  \\\n",
       "0       West South Central    ANGELINA       South                    8B   \n",
       "1       East South Central   JEFFERSON       South                    9A   \n",
       "2       East South Central   JEFFERSON       South                    9A   \n",
       "3       East South Central   JEFFERSON       South                    9A   \n",
       "4       East South Central   JEFFERSON       South                    9A   \n",
       "...                    ...         ...         ...                   ...   \n",
       "122951      South Atlantic        POLK       South                    9A   \n",
       "122952      South Atlantic        POLK       South                    9A   \n",
       "122953      South Atlantic    BERKELEY       South                    9A   \n",
       "122954  East South Central      SHELBY       South                    1B   \n",
       "122955      South Atlantic    BERKELEY       South                    9A   \n",
       "\n",
       "       offense_code offender_race offender_ethnicity  offender_age  \\\n",
       "0               26B       Unknown            Unknown           0.0   \n",
       "1               23H       Unknown            Unknown           0.0   \n",
       "2               23H       Unknown            Unknown           0.0   \n",
       "3               23H       Unknown            Unknown           0.0   \n",
       "4               23F       Unknown            Unknown           0.0   \n",
       "...             ...           ...                ...           ...   \n",
       "122951          23F       Unknown            Unknown           0.0   \n",
       "122952          23F       Unknown            Unknown           0.0   \n",
       "122953          240       Unknown            Unknown           0.0   \n",
       "122954          23F       Unknown            Unknown           0.0   \n",
       "122955          240       Unknown            Unknown           0.0   \n",
       "\n",
       "       offender_sex victim_type_code  location_code weapon_code  \\\n",
       "0                 U                I             25          95   \n",
       "1                 U                I             20          95   \n",
       "2                 U                I             20          95   \n",
       "3                 U                I             20          95   \n",
       "4                 U                I             20          95   \n",
       "...             ...              ...            ...         ...   \n",
       "122951            U                B             25          95   \n",
       "122952            U                B             25          95   \n",
       "122953            U                B             18          95   \n",
       "122954            U                B              7          95   \n",
       "122955            U                B             18          95   \n",
       "\n",
       "        prop_desc_code  stolen_value  recovered_flag  \n",
       "0                   20         375.0           False  \n",
       "1                   77           1.0           False  \n",
       "2                   65           0.0           False  \n",
       "3                   13         320.0           False  \n",
       "4                   77           1.0           False  \n",
       "...                ...           ...             ...  \n",
       "122951              37       10000.0            True  \n",
       "122952              36          35.0           False  \n",
       "122953              78       20000.0            True  \n",
       "122954               2          32.0           False  \n",
       "122955              77       27000.0            True  \n",
       "\n",
       "[122956 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import our CSV\n",
    "\n",
    "fbi_df1 = pd.read_csv(\"../../SQL_And_CSV/BinaryClassifier.csv\")\n",
    "fbi_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c3f66d-353d-4e95-b203-a83ad474054b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_agency_name</th>\n",
       "      <th>agency_type_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>division_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>region_name</th>\n",
       "      <th>population_group_code</th>\n",
       "      <th>offense_code</th>\n",
       "      <th>offender_race</th>\n",
       "      <th>offender_ethnicity</th>\n",
       "      <th>offender_age</th>\n",
       "      <th>offender_sex</th>\n",
       "      <th>victim_type_code</th>\n",
       "      <th>location_code</th>\n",
       "      <th>weapon_code</th>\n",
       "      <th>prop_desc_code</th>\n",
       "      <th>stolen_value</th>\n",
       "      <th>recovered_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angelina</td>\n",
       "      <td>County</td>\n",
       "      <td>Texas</td>\n",
       "      <td>West South Central</td>\n",
       "      <td>ANGELINA</td>\n",
       "      <td>South</td>\n",
       "      <td>8B</td>\n",
       "      <td>26B</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>20</td>\n",
       "      <td>375.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pub_agency_name agency_type_name state_name       division_name county_name  \\\n",
       "0        Angelina           County      Texas  West South Central    ANGELINA   \n",
       "1       Jefferson           County    Alabama  East South Central   JEFFERSON   \n",
       "2       Jefferson           County    Alabama  East South Central   JEFFERSON   \n",
       "3       Jefferson           County    Alabama  East South Central   JEFFERSON   \n",
       "4       Jefferson           County    Alabama  East South Central   JEFFERSON   \n",
       "\n",
       "  region_name population_group_code offense_code offender_race  \\\n",
       "0       South                    8B          26B       Unknown   \n",
       "1       South                    9A          23H       Unknown   \n",
       "2       South                    9A          23H       Unknown   \n",
       "3       South                    9A          23H       Unknown   \n",
       "4       South                    9A          23F       Unknown   \n",
       "\n",
       "  offender_ethnicity  offender_age offender_sex victim_type_code  \\\n",
       "0            Unknown           0.0            U                I   \n",
       "1            Unknown           0.0            U                I   \n",
       "2            Unknown           0.0            U                I   \n",
       "3            Unknown           0.0            U                I   \n",
       "4            Unknown           0.0            U                I   \n",
       "\n",
       "   location_code weapon_code  prop_desc_code  stolen_value  recovered_flag  \n",
       "0             25          95              20         375.0           False  \n",
       "1             20          95              77           1.0           False  \n",
       "2             20          95              65           0.0           False  \n",
       "3             20          95              13         320.0           False  \n",
       "4             20          95              77           1.0           False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop extra index\n",
    "fbi_df1 = fbi_df1.drop(labels =\"Unnamed: 0\",axis =1)\n",
    "fbi_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e5203b-72a6-4c10-ba0c-3c8d5b3e3b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_type_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>region_name</th>\n",
       "      <th>population_group_code</th>\n",
       "      <th>offense_code</th>\n",
       "      <th>offender_race</th>\n",
       "      <th>offender_ethnicity</th>\n",
       "      <th>offender_age</th>\n",
       "      <th>offender_sex</th>\n",
       "      <th>victim_type_code</th>\n",
       "      <th>location_code</th>\n",
       "      <th>weapon_code</th>\n",
       "      <th>prop_desc_code</th>\n",
       "      <th>stolen_value</th>\n",
       "      <th>recovered_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>County</td>\n",
       "      <td>Texas</td>\n",
       "      <td>South</td>\n",
       "      <td>8B</td>\n",
       "      <td>26B</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>20</td>\n",
       "      <td>375.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agency_type_name state_name region_name population_group_code offense_code  \\\n",
       "0           County      Texas       South                    8B          26B   \n",
       "1           County    Alabama       South                    9A          23H   \n",
       "2           County    Alabama       South                    9A          23H   \n",
       "3           County    Alabama       South                    9A          23H   \n",
       "4           County    Alabama       South                    9A          23F   \n",
       "\n",
       "  offender_race offender_ethnicity  offender_age offender_sex  \\\n",
       "0       Unknown            Unknown           0.0            U   \n",
       "1       Unknown            Unknown           0.0            U   \n",
       "2       Unknown            Unknown           0.0            U   \n",
       "3       Unknown            Unknown           0.0            U   \n",
       "4       Unknown            Unknown           0.0            U   \n",
       "\n",
       "  victim_type_code  location_code weapon_code  prop_desc_code  stolen_value  \\\n",
       "0                I             25          95              20         375.0   \n",
       "1                I             20          95              77           1.0   \n",
       "2                I             20          95              65           0.0   \n",
       "3                I             20          95              13         320.0   \n",
       "4                I             20          95              77           1.0   \n",
       "\n",
       "   recovered_flag  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pub_agency_name, county_name and division_name large and may confuse model. Probably not necessary as state_name and agency_type_name will give the same general info\n",
    "#that is to say, COUNTY v CITY, and REGION\n",
    "to_drop = [\"pub_agency_name\",\"division_name\", \"county_name\"]\n",
    "fbi_df2 = fbi_df1.drop(labels = to_drop, axis = 1)\n",
    "fbi_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da3ef3e-b80b-41b5-bb7f-766bbe730b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there's a lot of categorical data here. Checking for potential bucketing.\n",
    "#location_code, weapon_code and prop_desc_code are all categorical despite being mostly numerical\n",
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9dc31d9-7d3e-4f58-bf4b-e946f948ca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "North Carolina          26784\n",
       "Ohio                    11927\n",
       "Massachusetts           10788\n",
       "Texas                   10233\n",
       "Georgia                  9850\n",
       "Tennessee                4891\n",
       "South Carolina           4596\n",
       "Virginia                 4468\n",
       "Michigan                 3772\n",
       "Alabama                  3393\n",
       "West Virginia            3383\n",
       "Maryland                 2419\n",
       "Nevada                   2308\n",
       "Pennsylvania             2263\n",
       "Missouri                 2145\n",
       "Indiana                  1581\n",
       "New Mexico               1518\n",
       "Oregon                   1437\n",
       "California               1375\n",
       "Washington               1372\n",
       "Colorado                 1367\n",
       "New Jersey               1359\n",
       "Illinois                 1350\n",
       "Arkansas                 1292\n",
       "Florida                  1283\n",
       "Mississippi              1232\n",
       "Kentucky                  804\n",
       "Iowa                      531\n",
       "Connecticut               388\n",
       "Nebraska                  343\n",
       "Rhode Island              305\n",
       "Wisconsin                 283\n",
       "Arizona                   278\n",
       "Montana                   216\n",
       "Idaho                     210\n",
       "Delaware                  191\n",
       "North Dakota              183\n",
       "South Dakota              170\n",
       "Utah                      138\n",
       "Minnesota                 126\n",
       "New York                  126\n",
       "New Hampshire             100\n",
       "Alaska                     43\n",
       "Maine                      40\n",
       "Vermont                    39\n",
       "Oklahoma                   30\n",
       "Federal                    12\n",
       "Wyoming                     8\n",
       "District of Columbia        4\n",
       "Hawaii                      2\n",
       "Name: state_name, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copying for states name\n",
    "#checking state name\n",
    "states_counts = fbi_df2.state_name.value_counts()\n",
    "states_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f270478-7e50-450f-8a85-631749b1925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check density to see where to bucket\n",
    "states_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c753def7-0583-48d8-93fa-8612159bb565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "North Carolina                 26784\n",
       "Ohio                           11927\n",
       "Massachusetts                  10788\n",
       "Texas                          10233\n",
       "Georgia                         9850\n",
       "Tennessee                       4891\n",
       "South Carolina                  4596\n",
       "Other_US_States/Territories     4570\n",
       "Virginia                        4468\n",
       "Michigan                        3772\n",
       "Alabama                         3393\n",
       "West Virginia                   3383\n",
       "Maryland                        2419\n",
       "Nevada                          2308\n",
       "Pennsylvania                    2263\n",
       "Missouri                        2145\n",
       "Indiana                         1581\n",
       "New Mexico                      1518\n",
       "Oregon                          1437\n",
       "California                      1375\n",
       "Washington                      1372\n",
       "Colorado                        1367\n",
       "New Jersey                      1359\n",
       "Illinois                        1350\n",
       "Arkansas                        1292\n",
       "Florida                         1283\n",
       "Mississippi                     1232\n",
       "Name: state_name, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try cutting off at 1,000 and call it \"Other US States/Territories\"\n",
    "replacements = list(states_counts[states_counts < 1000].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for state in replacements:\n",
    "    fbi_df2.state_name = fbi_df2.state_name.replace(state,\"Other_US_States/Territories\")\n",
    "\n",
    "\n",
    "# Check to make sure data succesfully binned\n",
    "fbi_df2.state_name.value_counts()\n",
    "#there must be something going on in North Carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d95c83a-fa03-4677-8ec8-d5da4603ceab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                     87166\n",
       "County                   33065\n",
       "State Police               877\n",
       "University or College      721\n",
       "Other                      658\n",
       "Other State Agency         397\n",
       "Tribal                      60\n",
       "Federal                     12\n",
       "Name: agency_type_name, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's check agency types\n",
    "agency_counts = fbi_df2.agency_type_name.value_counts()\n",
    "\n",
    "agency_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3654b-5de6-457f-99e3-ea18e3d4580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan from here on out is to bucket as much as possible, then encode and run the three different model types on it. if it doesn't work, try a sigmoid model, \n",
    "#and if that doesn't accuracy, take the best model and write a report on it/how it got there. current winner is medium sized model on first data set 3-3-1 relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49523d3-911c-4975-a26b-f347c0913e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agency_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49c1011c-ce0a-41d0-9c99-653af481ada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                     87166\n",
       "County                   33065\n",
       "Tribal/Federal/Other      1127\n",
       "State Police               877\n",
       "University or College      721\n",
       "Name: agency_type_name, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try cutting off at 700 and call it \"Tribal/Federal/Other\n",
    "replacements = list(agency_counts[agency_counts < 700].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for agency in replacements:\n",
    "    fbi_df2.agency_type_name = fbi_df2.agency_type_name.replace(agency,\"Tribal/Federal/Other\")\n",
    "\n",
    "\n",
    "# Check to make sure data succesfully binned\n",
    "fbi_df2.agency_type_name.value_counts()\n",
    "#there must be something going on in North Carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f586c9b8-6e59-4214-9733-af76533f2127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agency_type_name          object\n",
       "state_name                object\n",
       "region_name               object\n",
       "population_group_code     object\n",
       "offense_code              object\n",
       "offender_race             object\n",
       "offender_ethnicity        object\n",
       "offender_age             float64\n",
       "offender_sex              object\n",
       "victim_type_code          object\n",
       "location_code              int64\n",
       "weapon_code               object\n",
       "prop_desc_code             int64\n",
       "stolen_value             float64\n",
       "recovered_flag             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make our target column binary for the encoder\n",
    "\n",
    "fbi_df2.recovered_flag = fbi_df2.recovered_flag.replace({True:1,False:0})\n",
    "#check to see if worked\n",
    "fbi_df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "886bc13e-a7b8-47d2-b68f-6bb48ae070d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agency_type_name', 'state_name', 'region_name', 'population_group_code', 'offense_code', 'offender_race', 'offender_ethnicity', 'offender_sex', 'victim_type_code', 'weapon_code']\n"
     ]
    }
   ],
   "source": [
    "#with an additional set of bucketing done, it's time to go ahead and make everything binary\n",
    "object_columns = fbi_df2.dtypes[fbi_df2.dtypes == \"object\"].index.tolist()\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30b949d-28ed-4582-9831-4797b7a97d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_type_name_City</th>\n",
       "      <th>agency_type_name_County</th>\n",
       "      <th>agency_type_name_State Police</th>\n",
       "      <th>agency_type_name_Tribal/Federal/Other</th>\n",
       "      <th>agency_type_name_University or College</th>\n",
       "      <th>state_name_Alabama</th>\n",
       "      <th>state_name_Arkansas</th>\n",
       "      <th>state_name_California</th>\n",
       "      <th>state_name_Colorado</th>\n",
       "      <th>state_name_Florida</th>\n",
       "      <th>...</th>\n",
       "      <th>weapon_code_20</th>\n",
       "      <th>weapon_code_30</th>\n",
       "      <th>weapon_code_35</th>\n",
       "      <th>weapon_code_40</th>\n",
       "      <th>weapon_code_50</th>\n",
       "      <th>weapon_code_70</th>\n",
       "      <th>weapon_code_85</th>\n",
       "      <th>weapon_code_90</th>\n",
       "      <th>weapon_code_95</th>\n",
       "      <th>weapon_code_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agency_type_name_City  agency_type_name_County  \\\n",
       "0                    0.0                      1.0   \n",
       "1                    0.0                      1.0   \n",
       "2                    0.0                      1.0   \n",
       "3                    0.0                      1.0   \n",
       "4                    0.0                      1.0   \n",
       "\n",
       "   agency_type_name_State Police  agency_type_name_Tribal/Federal/Other  \\\n",
       "0                            0.0                                    0.0   \n",
       "1                            0.0                                    0.0   \n",
       "2                            0.0                                    0.0   \n",
       "3                            0.0                                    0.0   \n",
       "4                            0.0                                    0.0   \n",
       "\n",
       "   agency_type_name_University or College  state_name_Alabama  \\\n",
       "0                                     0.0                 0.0   \n",
       "1                                     0.0                 1.0   \n",
       "2                                     0.0                 1.0   \n",
       "3                                     0.0                 1.0   \n",
       "4                                     0.0                 1.0   \n",
       "\n",
       "   state_name_Arkansas  state_name_California  state_name_Colorado  \\\n",
       "0                  0.0                    0.0                  0.0   \n",
       "1                  0.0                    0.0                  0.0   \n",
       "2                  0.0                    0.0                  0.0   \n",
       "3                  0.0                    0.0                  0.0   \n",
       "4                  0.0                    0.0                  0.0   \n",
       "\n",
       "   state_name_Florida  ...  weapon_code_20  weapon_code_30  weapon_code_35  \\\n",
       "0                 0.0  ...             0.0             0.0             0.0   \n",
       "1                 0.0  ...             0.0             0.0             0.0   \n",
       "2                 0.0  ...             0.0             0.0             0.0   \n",
       "3                 0.0  ...             0.0             0.0             0.0   \n",
       "4                 0.0  ...             0.0             0.0             0.0   \n",
       "\n",
       "   weapon_code_40  weapon_code_50  weapon_code_70  weapon_code_85  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   weapon_code_90  weapon_code_95  weapon_code_99  \n",
       "0             0.0             1.0             0.0  \n",
       "1             0.0             1.0             0.0  \n",
       "2             0.0             1.0             0.0  \n",
       "3             0.0             1.0             0.0  \n",
       "4             0.0             1.0             0.0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deploying the OHE produced earlier to make the conversions\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(fbi_df2[object_columns]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names_out(object_columns)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe7a8f0-2cb7-4458-bc94-15528f585993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offender_age</th>\n",
       "      <th>location_code</th>\n",
       "      <th>prop_desc_code</th>\n",
       "      <th>stolen_value</th>\n",
       "      <th>recovered_flag</th>\n",
       "      <th>agency_type_name_City</th>\n",
       "      <th>agency_type_name_County</th>\n",
       "      <th>agency_type_name_State Police</th>\n",
       "      <th>agency_type_name_Tribal/Federal/Other</th>\n",
       "      <th>agency_type_name_University or College</th>\n",
       "      <th>...</th>\n",
       "      <th>weapon_code_20</th>\n",
       "      <th>weapon_code_30</th>\n",
       "      <th>weapon_code_35</th>\n",
       "      <th>weapon_code_40</th>\n",
       "      <th>weapon_code_50</th>\n",
       "      <th>weapon_code_70</th>\n",
       "      <th>weapon_code_85</th>\n",
       "      <th>weapon_code_90</th>\n",
       "      <th>weapon_code_95</th>\n",
       "      <th>weapon_code_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   offender_age  location_code  prop_desc_code  stolen_value  recovered_flag  \\\n",
       "0           0.0             25              20         375.0               0   \n",
       "1           0.0             20              77           1.0               0   \n",
       "2           0.0             20              65           0.0               0   \n",
       "3           0.0             20              13         320.0               0   \n",
       "4           0.0             20              77           1.0               0   \n",
       "\n",
       "   agency_type_name_City  agency_type_name_County  \\\n",
       "0                    0.0                      1.0   \n",
       "1                    0.0                      1.0   \n",
       "2                    0.0                      1.0   \n",
       "3                    0.0                      1.0   \n",
       "4                    0.0                      1.0   \n",
       "\n",
       "   agency_type_name_State Police  agency_type_name_Tribal/Federal/Other  \\\n",
       "0                            0.0                                    0.0   \n",
       "1                            0.0                                    0.0   \n",
       "2                            0.0                                    0.0   \n",
       "3                            0.0                                    0.0   \n",
       "4                            0.0                                    0.0   \n",
       "\n",
       "   agency_type_name_University or College  ...  weapon_code_20  \\\n",
       "0                                     0.0  ...             0.0   \n",
       "1                                     0.0  ...             0.0   \n",
       "2                                     0.0  ...             0.0   \n",
       "3                                     0.0  ...             0.0   \n",
       "4                                     0.0  ...             0.0   \n",
       "\n",
       "   weapon_code_30  weapon_code_35  weapon_code_40  weapon_code_50  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   weapon_code_70  weapon_code_85  weapon_code_90  weapon_code_95  \\\n",
       "0             0.0             0.0             0.0             1.0   \n",
       "1             0.0             0.0             0.0             1.0   \n",
       "2             0.0             0.0             0.0             1.0   \n",
       "3             0.0             0.0             0.0             1.0   \n",
       "4             0.0             0.0             0.0             1.0   \n",
       "\n",
       "   weapon_code_99  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take the encoded dataframe and add it back into the original, then drop the changed columns\n",
    "fbi_df2 = fbi_df2.merge(encode_df, left_index=True, right_index = True)\n",
    "fbi_df2= fbi_df2.drop(labels =object_columns,axis=1)\n",
    "fbi_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "895cb645-a2ed-44a7-b39b-b9964e5ed4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    119\n",
      "int64        3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fbi_df2.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e180147e-759e-48f6-af5b-a642472d3801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with an additional set of bucketing done, it's time to go ahead and try some models\n",
    "#SPLIT THE DATA FOR TESTING AND TRAINING\n",
    "y = fbi_df2[\"recovered_flag\"].values\n",
    "X = fbi_df2.drop(labels =\"recovered_flag\",axis =1).values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c382928-7c31-4f58-aa95-af72a93212b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8699aed2-0d68-4e2d-afc8-2784b538a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 854       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 909\n",
      "Trainable params: 909\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#time to define the first new model with our slightly modified data.\n",
    "#start with basic 3-3-1\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 7\n",
    "hidden_nodes_layer2 = 6\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features,activation=\"relu\"))\n",
    "       \n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2 ,activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c109a70b-6ad4-4d15-adef-9b474e91b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66697f16-c724-4120-a2f5-2732015a6c42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 48.5115 - accuracy: 0.8109\n",
      "Epoch 2/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 59.6593 - accuracy: 0.8022\n",
      "Epoch 3/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 97.3897 - accuracy: 0.8002\n",
      "Epoch 4/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 138.7034 - accuracy: 0.8055\n",
      "Epoch 5/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 79.2328 - accuracy: 0.8152\n",
      "Epoch 6/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 87.7117 - accuracy: 0.8317\n",
      "Epoch 7/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 52.9449 - accuracy: 0.8391\n",
      "Epoch 8/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 16.2572 - accuracy: 0.8284\n",
      "Epoch 9/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 9.9617 - accuracy: 0.8077\n",
      "Epoch 10/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 8.8588 - accuracy: 0.8248\n",
      "Epoch 11/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 39.4067 - accuracy: 0.8162\n",
      "Epoch 12/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 7.9842 - accuracy: 0.7858\n",
      "Epoch 13/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 4.5819 - accuracy: 0.8285\n",
      "Epoch 14/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 14.8274 - accuracy: 0.8014\n",
      "Epoch 15/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 16.1074 - accuracy: 0.8380\n",
      "Epoch 16/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 2.1647 - accuracy: 0.8039\n",
      "Epoch 17/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.9639 - accuracy: 0.8412\n",
      "Epoch 18/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 7.0813 - accuracy: 0.8579\n",
      "Epoch 19/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4809 - accuracy: 0.8572\n",
      "Epoch 20/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3484 - accuracy: 0.8578\n",
      "Epoch 21/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3499 - accuracy: 0.8576\n",
      "Epoch 22/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3516 - accuracy: 0.8573\n",
      "Epoch 23/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3509 - accuracy: 0.8570\n",
      "Epoch 24/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3496 - accuracy: 0.8576\n",
      "Epoch 25/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3494 - accuracy: 0.8579\n",
      "Epoch 26/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3490 - accuracy: 0.8573\n",
      "Epoch 27/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3486 - accuracy: 0.8581\n",
      "Epoch 28/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3473 - accuracy: 0.8575\n",
      "Epoch 29/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3470 - accuracy: 0.8579\n",
      "Epoch 30/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3469 - accuracy: 0.8578\n",
      "Epoch 31/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3472 - accuracy: 0.8581\n",
      "Epoch 32/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3468 - accuracy: 0.8580\n",
      "Epoch 33/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3449 - accuracy: 0.8578\n",
      "Epoch 34/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3457 - accuracy: 0.8577\n",
      "Epoch 35/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3438 - accuracy: 0.8578\n",
      "Epoch 36/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3440 - accuracy: 0.8585\n",
      "Epoch 37/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3423 - accuracy: 0.8580\n",
      "Epoch 38/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3431 - accuracy: 0.8581\n",
      "Epoch 39/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3436 - accuracy: 0.8582\n",
      "Epoch 40/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3419 - accuracy: 0.8578\n",
      "Epoch 41/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3424 - accuracy: 0.8582\n",
      "Epoch 42/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3461 - accuracy: 0.8582\n",
      "Epoch 43/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3412 - accuracy: 0.8584\n",
      "Epoch 44/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3436 - accuracy: 0.8582\n",
      "Epoch 45/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3414 - accuracy: 0.8585\n",
      "Epoch 46/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3432 - accuracy: 0.8587\n",
      "Epoch 47/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3434 - accuracy: 0.8590\n",
      "Epoch 48/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3394 - accuracy: 0.8589\n",
      "Epoch 49/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3450 - accuracy: 0.8593\n",
      "Epoch 50/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3412 - accuracy: 0.8592\n",
      "Epoch 51/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3404 - accuracy: 0.8593\n",
      "Epoch 52/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3405 - accuracy: 0.8593\n",
      "Epoch 53/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3397 - accuracy: 0.8597\n",
      "Epoch 54/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3375 - accuracy: 0.8602\n",
      "Epoch 55/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3391 - accuracy: 0.8602\n",
      "Epoch 56/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3407 - accuracy: 0.8602\n",
      "Epoch 57/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.5812 - accuracy: 0.8591\n",
      "Epoch 58/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3592 - accuracy: 0.8598\n",
      "Epoch 59/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3567 - accuracy: 0.8598\n",
      "Epoch 60/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3474 - accuracy: 0.8599\n",
      "Epoch 61/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3360 - accuracy: 0.8599\n",
      "Epoch 62/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3376 - accuracy: 0.8603\n",
      "Epoch 63/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3383 - accuracy: 0.8605\n",
      "Epoch 64/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3368 - accuracy: 0.8603\n",
      "Epoch 65/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3427 - accuracy: 0.8604\n",
      "Epoch 66/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3436 - accuracy: 0.8602\n",
      "Epoch 67/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3346 - accuracy: 0.8604\n",
      "Epoch 68/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3376 - accuracy: 0.8604\n",
      "Epoch 69/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3382 - accuracy: 0.8601\n",
      "Epoch 70/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3348 - accuracy: 0.8603\n",
      "Epoch 71/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3368 - accuracy: 0.8604\n",
      "Epoch 72/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3366 - accuracy: 0.8605\n",
      "Epoch 73/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3374 - accuracy: 0.8606\n",
      "Epoch 74/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3387 - accuracy: 0.8607\n",
      "Epoch 75/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3370 - accuracy: 0.8604\n",
      "Epoch 76/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3388 - accuracy: 0.8606\n",
      "Epoch 77/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3388 - accuracy: 0.8607\n",
      "Epoch 78/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3385 - accuracy: 0.8606\n",
      "Epoch 79/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3373 - accuracy: 0.8608\n",
      "Epoch 80/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3400 - accuracy: 0.8606\n",
      "Epoch 81/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3377 - accuracy: 0.8607\n",
      "Epoch 82/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3353 - accuracy: 0.8608\n",
      "Epoch 83/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3354 - accuracy: 0.8608\n",
      "Epoch 84/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3340 - accuracy: 0.8606\n",
      "Epoch 85/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3390 - accuracy: 0.8608\n",
      "Epoch 86/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3338 - accuracy: 0.8607\n",
      "Epoch 87/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3366 - accuracy: 0.8608\n",
      "Epoch 88/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3360 - accuracy: 0.8609\n",
      "Epoch 89/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3375 - accuracy: 0.8608\n",
      "Epoch 90/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3341 - accuracy: 0.8609\n",
      "Epoch 91/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3348 - accuracy: 0.8609\n",
      "Epoch 92/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3339 - accuracy: 0.8608\n",
      "Epoch 93/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3354 - accuracy: 0.8609\n",
      "Epoch 94/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3351 - accuracy: 0.8607\n",
      "Epoch 95/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3354 - accuracy: 0.8609\n",
      "Epoch 96/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3353 - accuracy: 0.8609\n",
      "Epoch 97/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8610\n",
      "Epoch 98/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3388 - accuracy: 0.8608\n",
      "Epoch 99/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3336 - accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3335 - accuracy: 0.8608\n"
     ]
    }
   ],
   "source": [
    "#Train the Model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0bf522d-4e34-47f7-b620-942e06fd8eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961/961 - 1s - loss: 0.7619 - accuracy: 0.7471 - 814ms/epoch - 847us/step\n",
      "Loss: 0.7618681192398071, Accuracy: 0.7470965385437012\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "#terible horrible no good! bummer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08e4fd72-359a-4e06-a67d-e89216f9eca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 7)                 854       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 951\n",
      "Trainable params: 951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#let's try the massive model out\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 7\n",
    "hidden_nodes_layer2 = 6\n",
    "hidden_nodes_layer3 = 6\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features,activation=\"relu\"))\n",
    "       \n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2 ,activation=\"relu\"))\n",
    "\n",
    "#Third hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e578316-a3b2-4530-96c0-78f2ce5578d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e54cb104-78aa-45bc-8cd8-c6d63b3ebf8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.8229 - accuracy: 0.8399\n",
      "Epoch 2/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3526 - accuracy: 0.8591\n",
      "Epoch 3/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3473 - accuracy: 0.8591\n",
      "Epoch 4/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3481 - accuracy: 0.8592\n",
      "Epoch 5/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3433 - accuracy: 0.8592\n",
      "Epoch 6/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3399 - accuracy: 0.8592\n",
      "Epoch 7/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3388 - accuracy: 0.8594\n",
      "Epoch 8/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3364 - accuracy: 0.8598\n",
      "Epoch 9/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3373 - accuracy: 0.8598\n",
      "Epoch 10/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3511 - accuracy: 0.8597\n",
      "Epoch 11/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3348 - accuracy: 0.8601\n",
      "Epoch 12/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3361 - accuracy: 0.8600\n",
      "Epoch 13/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3334 - accuracy: 0.8600\n",
      "Epoch 14/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3393 - accuracy: 0.8604\n",
      "Epoch 15/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3308 - accuracy: 0.8604\n",
      "Epoch 16/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3318 - accuracy: 0.8602\n",
      "Epoch 17/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3320 - accuracy: 0.8604\n",
      "Epoch 18/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3331 - accuracy: 0.8601\n",
      "Epoch 19/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3425 - accuracy: 0.8602\n",
      "Epoch 20/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3331 - accuracy: 0.8605\n",
      "Epoch 21/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3321 - accuracy: 0.8604\n",
      "Epoch 22/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3309 - accuracy: 0.8607\n",
      "Epoch 23/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3309 - accuracy: 0.8606\n",
      "Epoch 24/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3309 - accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3319 - accuracy: 0.8608\n",
      "Epoch 26/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3301 - accuracy: 0.8610\n",
      "Epoch 27/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3327 - accuracy: 0.8609\n",
      "Epoch 28/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3298 - accuracy: 0.8606\n",
      "Epoch 29/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3312 - accuracy: 0.8609\n",
      "Epoch 30/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3280 - accuracy: 0.8619\n",
      "Epoch 31/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3288 - accuracy: 0.8613\n",
      "Epoch 32/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3304 - accuracy: 0.8616\n",
      "Epoch 33/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3286 - accuracy: 0.8613\n",
      "Epoch 34/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3273 - accuracy: 0.8621\n",
      "Epoch 35/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3282 - accuracy: 0.8617\n",
      "Epoch 36/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3274 - accuracy: 0.8626\n",
      "Epoch 37/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3350 - accuracy: 0.8613\n",
      "Epoch 38/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3252 - accuracy: 0.8620\n",
      "Epoch 39/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3279 - accuracy: 0.8624\n",
      "Epoch 40/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3274 - accuracy: 0.8625\n",
      "Epoch 41/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3264 - accuracy: 0.8626\n",
      "Epoch 42/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3260 - accuracy: 0.8622\n",
      "Epoch 43/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3266 - accuracy: 0.8627\n",
      "Epoch 44/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3273 - accuracy: 0.8629\n",
      "Epoch 45/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3260 - accuracy: 0.8630\n",
      "Epoch 46/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3305 - accuracy: 0.8628\n",
      "Epoch 47/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3256 - accuracy: 0.8630\n",
      "Epoch 48/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3259 - accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3265 - accuracy: 0.8631\n",
      "Epoch 50/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3260 - accuracy: 0.8621\n",
      "Epoch 51/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3313 - accuracy: 0.8577\n",
      "Epoch 52/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3339 - accuracy: 0.8616\n",
      "Epoch 53/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3245 - accuracy: 0.8620\n",
      "Epoch 54/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3275 - accuracy: 0.8619\n",
      "Epoch 55/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3249 - accuracy: 0.8617\n",
      "Epoch 56/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3255 - accuracy: 0.8621\n",
      "Epoch 57/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3251 - accuracy: 0.8622\n",
      "Epoch 58/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3270 - accuracy: 0.8619\n",
      "Epoch 59/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3269 - accuracy: 0.8619\n",
      "Epoch 60/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3262 - accuracy: 0.8622\n",
      "Epoch 61/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3249 - accuracy: 0.8622\n",
      "Epoch 62/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3242 - accuracy: 0.8622\n",
      "Epoch 63/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3242 - accuracy: 0.8624\n",
      "Epoch 64/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3252 - accuracy: 0.8624\n",
      "Epoch 65/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3248 - accuracy: 0.8621\n",
      "Epoch 66/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3281 - accuracy: 0.8619\n",
      "Epoch 67/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3249 - accuracy: 0.8620\n",
      "Epoch 68/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3297 - accuracy: 0.8618\n",
      "Epoch 69/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3297 - accuracy: 0.8617\n",
      "Epoch 70/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3234 - accuracy: 0.8621\n",
      "Epoch 71/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3238 - accuracy: 0.8619\n",
      "Epoch 72/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3232 - accuracy: 0.8624\n",
      "Epoch 73/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3260 - accuracy: 0.8624\n",
      "Epoch 74/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3294 - accuracy: 0.8622\n",
      "Epoch 75/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3236 - accuracy: 0.8621\n",
      "Epoch 76/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3243 - accuracy: 0.8618\n",
      "Epoch 77/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3232 - accuracy: 0.8622\n",
      "Epoch 78/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3247 - accuracy: 0.8622\n",
      "Epoch 79/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3227 - accuracy: 0.8624\n",
      "Epoch 80/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3232 - accuracy: 0.8628\n",
      "Epoch 81/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3253 - accuracy: 0.8624\n",
      "Epoch 82/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3227 - accuracy: 0.8622\n",
      "Epoch 83/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3244 - accuracy: 0.8623\n",
      "Epoch 84/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3229 - accuracy: 0.8624\n",
      "Epoch 85/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3242 - accuracy: 0.8626\n",
      "Epoch 86/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3225 - accuracy: 0.8627\n",
      "Epoch 87/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3235 - accuracy: 0.8626\n",
      "Epoch 88/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3242 - accuracy: 0.8623\n",
      "Epoch 89/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3242 - accuracy: 0.8627\n",
      "Epoch 90/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3216 - accuracy: 0.8632\n",
      "Epoch 91/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3213 - accuracy: 0.8630\n",
      "Epoch 92/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3240 - accuracy: 0.8630\n",
      "Epoch 93/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3221 - accuracy: 0.8632\n",
      "Epoch 94/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3214 - accuracy: 0.8629\n",
      "Epoch 95/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3217 - accuracy: 0.8627\n",
      "Epoch 96/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3290 - accuracy: 0.8632\n",
      "Epoch 97/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3212 - accuracy: 0.8632\n",
      "Epoch 98/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3219 - accuracy: 0.8633\n",
      "Epoch 99/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3210 - accuracy: 0.8633\n",
      "Epoch 100/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3221 - accuracy: 0.8631\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn2.fit(X_train,y_train,epochs=100)\n",
    "#re-doing forgot to change the model number on the output layer oops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b414d245-e040-44a9-86dd-71ff76009482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961/961 - 1s - loss: 1.5582 - accuracy: 0.6656 - 883ms/epoch - 919us/step\n",
      "Loss: 1.5582029819488525, Accuracy: 0.6656039357185364\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "#terible horrible no good! bummer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "042174b5-50cf-4bde-9370-c932f7456745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 6)                 732       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 739\n",
      "Trainable params: 739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#let's try a tiny model out\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 6\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features,activation=\"relu\"))\n",
    "       \n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ada84263-7375-4613-9283-cb6b6c16447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0295e64-3f22-4e17-a8f1-63f4e3ee6b42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 32.6151 - accuracy: 0.8295\n",
      "Epoch 2/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 8.0436 - accuracy: 0.8462\n",
      "Epoch 3/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 29.7226 - accuracy: 0.8392\n",
      "Epoch 4/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 7.1862 - accuracy: 0.8362\n",
      "Epoch 5/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 10.7125 - accuracy: 0.8419\n",
      "Epoch 6/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 6.8763 - accuracy: 0.8435\n",
      "Epoch 7/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 5.7944 - accuracy: 0.8452\n",
      "Epoch 8/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 7.0602 - accuracy: 0.8438\n",
      "Epoch 9/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 18.4935 - accuracy: 0.8393\n",
      "Epoch 10/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 19.3995 - accuracy: 0.8428\n",
      "Epoch 11/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 15.1232 - accuracy: 0.8417\n",
      "Epoch 12/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 21.7948 - accuracy: 0.8403\n",
      "Epoch 13/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 3.1494 - accuracy: 0.8487\n",
      "Epoch 14/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 44.8026 - accuracy: 0.8469\n",
      "Epoch 15/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 12.1426 - accuracy: 0.8218\n",
      "Epoch 16/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 4.9420 - accuracy: 0.8503\n",
      "Epoch 17/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 20.0801 - accuracy: 0.8165\n",
      "Epoch 18/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 29.2848 - accuracy: 0.8269\n",
      "Epoch 19/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 6.7194 - accuracy: 0.8473\n",
      "Epoch 20/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 26.9504 - accuracy: 0.8359\n",
      "Epoch 21/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 49.5831 - accuracy: 0.8369\n",
      "Epoch 22/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 5.3394 - accuracy: 0.8406\n",
      "Epoch 23/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 6.9945 - accuracy: 0.8529\n",
      "Epoch 24/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 3.8717 - accuracy: 0.8532\n",
      "Epoch 25/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 39.4248 - accuracy: 0.8555\n",
      "Epoch 26/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 13.3777 - accuracy: 0.8278\n",
      "Epoch 27/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 21.4263 - accuracy: 0.8419\n",
      "Epoch 28/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 4.4472 - accuracy: 0.8570\n",
      "Epoch 29/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 39.8696 - accuracy: 0.8375\n",
      "Epoch 30/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 18.4664 - accuracy: 0.8374\n",
      "Epoch 31/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 39.2498 - accuracy: 0.8495\n",
      "Epoch 32/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 4.6202 - accuracy: 0.8442\n",
      "Epoch 33/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 5.6656 - accuracy: 0.8553\n",
      "Epoch 34/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 7.1277 - accuracy: 0.8577\n",
      "Epoch 35/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 19.1839 - accuracy: 0.8490\n",
      "Epoch 36/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 4.7441 - accuracy: 0.8580\n",
      "Epoch 37/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 5.0548 - accuracy: 0.8567\n",
      "Epoch 38/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 22.0847 - accuracy: 0.8578\n",
      "Epoch 39/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 13.2046 - accuracy: 0.8444\n",
      "Epoch 40/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 1.2011 - accuracy: 0.8591\n",
      "Epoch 41/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 2.4832 - accuracy: 0.8566\n",
      "Epoch 42/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 6.8137 - accuracy: 0.8573\n",
      "Epoch 43/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 1.0632 - accuracy: 0.8593\n",
      "Epoch 44/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 45/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 46/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 47/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 48/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 49/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 50/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 51/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 52/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 53/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 54/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 55/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 56/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 57/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 58/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 59/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 60/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 61/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 62/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 63/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 64/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 65/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 66/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 67/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 68/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 69/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 70/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 71/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 72/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 73/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 74/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 75/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 76/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 77/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 78/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 79/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 80/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 81/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 82/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 83/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 84/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 85/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 86/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 87/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 88/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 89/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 90/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 91/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 92/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 93/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 94/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 95/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 96/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 97/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 98/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 99/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n",
      "Epoch 100/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.4063 - accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "#trying the small model\n",
    "fit_model = nn3.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3bf4ab3-52ff-481a-9650-bf8848b6ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961/961 - 1s - loss: 2.5904 - accuracy: 0.7356 - 850ms/epoch - 884us/step\n",
      "Loss: 2.590409994125366, Accuracy: 0.7356127500534058\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "#bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd7fbdd7-850b-4ff9-a7ea-c1623f979907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 4)                 488       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 519\n",
      "Trainable params: 519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#let's smaller but deeper\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 4\n",
    "hidden_nodes_layer2 = 3\n",
    "hidden_nodes_layer3 = 3\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features,activation=\"relu\"))\n",
    "       \n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2 ,activation=\"relu\"))\n",
    "\n",
    "#Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce1db899-4cf9-4f64-be23-39dd89c556a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn5.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4b2a7cb-461d-474c-929d-afeb8f6f6569",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.5195 - accuracy: 0.8593\n",
      "Epoch 2/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3660 - accuracy: 0.8593\n",
      "Epoch 3/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3762 - accuracy: 0.8593\n",
      "Epoch 4/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3748 - accuracy: 0.8593\n",
      "Epoch 5/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3602 - accuracy: 0.8593\n",
      "Epoch 6/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3586 - accuracy: 0.8593\n",
      "Epoch 7/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3668 - accuracy: 0.8593\n",
      "Epoch 8/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3540 - accuracy: 0.8593\n",
      "Epoch 9/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3431 - accuracy: 0.8593\n",
      "Epoch 10/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3540 - accuracy: 0.8593\n",
      "Epoch 11/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3510 - accuracy: 0.8593\n",
      "Epoch 12/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3471 - accuracy: 0.8593\n",
      "Epoch 13/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3645 - accuracy: 0.8593\n",
      "Epoch 14/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3472 - accuracy: 0.8593\n",
      "Epoch 15/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3495 - accuracy: 0.8593\n",
      "Epoch 16/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3485 - accuracy: 0.8593\n",
      "Epoch 17/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3512 - accuracy: 0.8593\n",
      "Epoch 18/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3500 - accuracy: 0.8593\n",
      "Epoch 19/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3412 - accuracy: 0.8593\n",
      "Epoch 20/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3432 - accuracy: 0.8593\n",
      "Epoch 21/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3470 - accuracy: 0.8593\n",
      "Epoch 22/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3398 - accuracy: 0.8593\n",
      "Epoch 23/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3393 - accuracy: 0.8593\n",
      "Epoch 24/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3384 - accuracy: 0.8593\n",
      "Epoch 25/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3391 - accuracy: 0.8593\n",
      "Epoch 26/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3417 - accuracy: 0.8593\n",
      "Epoch 27/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3377 - accuracy: 0.8593\n",
      "Epoch 28/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3385 - accuracy: 0.8593\n",
      "Epoch 29/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3401 - accuracy: 0.8595\n",
      "Epoch 30/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3384 - accuracy: 0.8597\n",
      "Epoch 31/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3371 - accuracy: 0.8597\n",
      "Epoch 32/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3382 - accuracy: 0.8599\n",
      "Epoch 33/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3368 - accuracy: 0.8598\n",
      "Epoch 34/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3393 - accuracy: 0.8598\n",
      "Epoch 35/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3361 - accuracy: 0.8598\n",
      "Epoch 36/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3362 - accuracy: 0.8598\n",
      "Epoch 37/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3367 - accuracy: 0.8597\n",
      "Epoch 38/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3382 - accuracy: 0.8599\n",
      "Epoch 39/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3348 - accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3455 - accuracy: 0.8601\n",
      "Epoch 41/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3360 - accuracy: 0.8598\n",
      "Epoch 42/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3349 - accuracy: 0.8599\n",
      "Epoch 43/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3376 - accuracy: 0.8601\n",
      "Epoch 44/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3362 - accuracy: 0.8601\n",
      "Epoch 45/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3359 - accuracy: 0.8601\n",
      "Epoch 46/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3341 - accuracy: 0.8600\n",
      "Epoch 47/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3381 - accuracy: 0.8602\n",
      "Epoch 48/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3347 - accuracy: 0.8601\n",
      "Epoch 49/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8601\n",
      "Epoch 50/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3331 - accuracy: 0.8602\n",
      "Epoch 51/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3335 - accuracy: 0.8601\n",
      "Epoch 52/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3408 - accuracy: 0.8600\n",
      "Epoch 53/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3330 - accuracy: 0.8601\n",
      "Epoch 54/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3321 - accuracy: 0.8600\n",
      "Epoch 55/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3335 - accuracy: 0.8602\n",
      "Epoch 56/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3359 - accuracy: 0.8602\n",
      "Epoch 57/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8601\n",
      "Epoch 58/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3362 - accuracy: 0.8601\n",
      "Epoch 59/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8601\n",
      "Epoch 60/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3385 - accuracy: 0.8601\n",
      "Epoch 61/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3339 - accuracy: 0.8602\n",
      "Epoch 62/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3345 - accuracy: 0.8602\n",
      "Epoch 63/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3351 - accuracy: 0.8601\n",
      "Epoch 64/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8603\n",
      "Epoch 65/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3361 - accuracy: 0.8602\n",
      "Epoch 66/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3340 - accuracy: 0.8601\n",
      "Epoch 67/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3357 - accuracy: 0.8602\n",
      "Epoch 68/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8603\n",
      "Epoch 69/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3390 - accuracy: 0.8601\n",
      "Epoch 70/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3360 - accuracy: 0.8603\n",
      "Epoch 71/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3344 - accuracy: 0.8601\n",
      "Epoch 72/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3349 - accuracy: 0.8602\n",
      "Epoch 73/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8601\n",
      "Epoch 74/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3367 - accuracy: 0.8601\n",
      "Epoch 75/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3320 - accuracy: 0.8603\n",
      "Epoch 76/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3339 - accuracy: 0.8604\n",
      "Epoch 77/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3321 - accuracy: 0.8603\n",
      "Epoch 78/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3335 - accuracy: 0.8604\n",
      "Epoch 79/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3322 - accuracy: 0.8605\n",
      "Epoch 80/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3325 - accuracy: 0.8604\n",
      "Epoch 81/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3353 - accuracy: 0.8604\n",
      "Epoch 82/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3443 - accuracy: 0.8606\n",
      "Epoch 83/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3333 - accuracy: 0.8606\n",
      "Epoch 84/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3319 - accuracy: 0.8608\n",
      "Epoch 85/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3348 - accuracy: 0.8605\n",
      "Epoch 86/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3451 - accuracy: 0.8607\n",
      "Epoch 87/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 2.7605 - accuracy: 0.8607\n",
      "Epoch 88/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3316 - accuracy: 0.8608\n",
      "Epoch 89/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3411 - accuracy: 0.8607\n",
      "Epoch 90/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3368 - accuracy: 0.8608\n",
      "Epoch 91/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3380 - accuracy: 0.8609\n",
      "Epoch 92/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3319 - accuracy: 0.8610\n",
      "Epoch 93/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3333 - accuracy: 0.8609\n",
      "Epoch 94/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3312 - accuracy: 0.8610\n",
      "Epoch 95/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3340 - accuracy: 0.8610\n",
      "Epoch 96/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3330 - accuracy: 0.8610\n",
      "Epoch 97/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3368 - accuracy: 0.8608\n",
      "Epoch 98/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3302 - accuracy: 0.8612\n",
      "Epoch 99/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3304 - accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3320 - accuracy: 0.8613\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn5.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fb0a89a-546d-4b42-a345-7d9e16ed0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961/961 - 1s - loss: 5.2182 - accuracy: 0.5586 - 871ms/epoch - 906us/step\n",
      "Loss: 5.218200206756592, Accuracy: 0.558638870716095\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4588ed2-21ee-473b-97cb-d1367fa42bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 4)                 488       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 519\n",
      "Trainable params: 519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#let's just for fun ruin this by setting all activations to sigmoid and laugh our way to the bank.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 4\n",
    "hidden_nodes_layer2 = 3\n",
    "hidden_nodes_layer3 = 3\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features,activation=\"sigmoid\"))\n",
    "       \n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2 ,activation=\"sigmoid\"))\n",
    "\n",
    "#Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"sigmoid\"))\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "105fd0b5-720c-4608-9faa-e767e23631a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn6.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2130ca06-3ac7-4e59-8d83-804fd6c196be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.4094 - accuracy: 0.8593\n",
      "Epoch 2/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3853 - accuracy: 0.8593\n",
      "Epoch 3/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3719 - accuracy: 0.8593\n",
      "Epoch 4/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3602 - accuracy: 0.8592\n",
      "Epoch 5/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3573 - accuracy: 0.8593\n",
      "Epoch 6/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3550 - accuracy: 0.8592\n",
      "Epoch 7/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3597 - accuracy: 0.8592\n",
      "Epoch 8/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3536 - accuracy: 0.8592\n",
      "Epoch 9/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3532 - accuracy: 0.8594\n",
      "Epoch 10/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3494 - accuracy: 0.8592\n",
      "Epoch 11/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3495 - accuracy: 0.8592\n",
      "Epoch 12/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3657 - accuracy: 0.8593\n",
      "Epoch 13/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3550 - accuracy: 0.8590\n",
      "Epoch 14/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3535 - accuracy: 0.8592\n",
      "Epoch 15/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3525 - accuracy: 0.8593\n",
      "Epoch 16/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3683 - accuracy: 0.8593\n",
      "Epoch 17/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3627 - accuracy: 0.8604\n",
      "Epoch 18/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3576 - accuracy: 0.8589\n",
      "Epoch 19/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3508 - accuracy: 0.8600\n",
      "Epoch 20/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3649 - accuracy: 0.8600\n",
      "Epoch 21/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3518 - accuracy: 0.8595\n",
      "Epoch 22/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3507 - accuracy: 0.8603\n",
      "Epoch 23/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3504 - accuracy: 0.8601\n",
      "Epoch 24/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3530 - accuracy: 0.8599\n",
      "Epoch 25/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3531 - accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3493 - accuracy: 0.8603\n",
      "Epoch 27/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3541 - accuracy: 0.8591\n",
      "Epoch 28/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3535 - accuracy: 0.8604\n",
      "Epoch 29/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3526 - accuracy: 0.8592\n",
      "Epoch 30/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3489 - accuracy: 0.8600\n",
      "Epoch 31/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3560 - accuracy: 0.8602\n",
      "Epoch 32/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3623 - accuracy: 0.8604\n",
      "Epoch 33/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3561 - accuracy: 0.8600\n",
      "Epoch 34/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3446 - accuracy: 0.8609\n",
      "Epoch 35/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3505 - accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3496 - accuracy: 0.8608\n",
      "Epoch 37/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3492 - accuracy: 0.8610\n",
      "Epoch 38/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3498 - accuracy: 0.8601\n",
      "Epoch 39/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3488 - accuracy: 0.8596\n",
      "Epoch 40/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3477 - accuracy: 0.8604\n",
      "Epoch 41/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3498 - accuracy: 0.8611\n",
      "Epoch 42/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3560 - accuracy: 0.8606\n",
      "Epoch 43/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3468 - accuracy: 0.8607\n",
      "Epoch 44/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3475 - accuracy: 0.8611\n",
      "Epoch 45/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3558 - accuracy: 0.8613\n",
      "Epoch 46/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3577 - accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3483 - accuracy: 0.8611\n",
      "Epoch 48/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3539 - accuracy: 0.8612\n",
      "Epoch 49/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3466 - accuracy: 0.8618\n",
      "Epoch 50/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3517 - accuracy: 0.8614\n",
      "Epoch 51/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3471 - accuracy: 0.8608\n",
      "Epoch 52/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3449 - accuracy: 0.8613\n",
      "Epoch 53/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3481 - accuracy: 0.8612\n",
      "Epoch 54/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3474 - accuracy: 0.8602\n",
      "Epoch 55/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3491 - accuracy: 0.8604\n",
      "Epoch 56/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3467 - accuracy: 0.8611\n",
      "Epoch 57/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3475 - accuracy: 0.8594\n",
      "Epoch 58/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3503 - accuracy: 0.8615\n",
      "Epoch 59/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3503 - accuracy: 0.8606\n",
      "Epoch 60/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3470 - accuracy: 0.8602\n",
      "Epoch 61/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3454 - accuracy: 0.8605\n",
      "Epoch 62/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3502 - accuracy: 0.8615\n",
      "Epoch 63/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3507 - accuracy: 0.8607\n",
      "Epoch 64/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3455 - accuracy: 0.8610\n",
      "Epoch 65/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3479 - accuracy: 0.8612\n",
      "Epoch 66/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3449 - accuracy: 0.8617\n",
      "Epoch 67/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3506 - accuracy: 0.8618\n",
      "Epoch 68/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3462 - accuracy: 0.8601\n",
      "Epoch 69/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3461 - accuracy: 0.8608\n",
      "Epoch 70/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3458 - accuracy: 0.8611\n",
      "Epoch 71/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3469 - accuracy: 0.8611\n",
      "Epoch 72/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3492 - accuracy: 0.8610\n",
      "Epoch 73/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3475 - accuracy: 0.8612\n",
      "Epoch 74/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3506 - accuracy: 0.8617\n",
      "Epoch 75/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3495 - accuracy: 0.8601\n",
      "Epoch 76/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3474 - accuracy: 0.8609\n",
      "Epoch 77/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3482 - accuracy: 0.8613\n",
      "Epoch 78/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3455 - accuracy: 0.8612\n",
      "Epoch 79/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3425 - accuracy: 0.8597\n",
      "Epoch 80/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3448 - accuracy: 0.8602\n",
      "Epoch 81/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3472 - accuracy: 0.8608\n",
      "Epoch 82/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3488 - accuracy: 0.8602\n",
      "Epoch 83/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3464 - accuracy: 0.8613\n",
      "Epoch 84/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3459 - accuracy: 0.8610\n",
      "Epoch 85/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3444 - accuracy: 0.8613\n",
      "Epoch 86/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3424 - accuracy: 0.8609\n",
      "Epoch 87/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3427 - accuracy: 0.8602\n",
      "Epoch 88/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3426 - accuracy: 0.8601\n",
      "Epoch 89/100\n",
      "2882/2882 [==============================] - 4s 1ms/step - loss: 0.3449 - accuracy: 0.8606\n",
      "Epoch 90/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3575 - accuracy: 0.8609\n",
      "Epoch 91/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3440 - accuracy: 0.8609\n",
      "Epoch 92/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3439 - accuracy: 0.8609\n",
      "Epoch 93/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3466 - accuracy: 0.8608\n",
      "Epoch 94/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3469 - accuracy: 0.8612\n",
      "Epoch 95/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3476 - accuracy: 0.8617\n",
      "Epoch 96/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3460 - accuracy: 0.8595\n",
      "Epoch 97/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3443 - accuracy: 0.8608\n",
      "Epoch 98/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3407 - accuracy: 0.8606\n",
      "Epoch 99/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3443 - accuracy: 0.8607\n",
      "Epoch 100/100\n",
      "2882/2882 [==============================] - 3s 1ms/step - loss: 0.3465 - accuracy: 0.8610\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn6.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e966032-8132-4e23-b2c5-fc9e7f6152a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961/961 - 1s - loss: 0.6365 - accuracy: 0.3714 - 866ms/epoch - 902us/step\n",
      "Loss: 0.6364541053771973, Accuracy: 0.37144994735717773\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10bea59a-1985-4b31-8dec-2efa5001026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offender_age</th>\n",
       "      <th>location_code</th>\n",
       "      <th>prop_desc_code</th>\n",
       "      <th>stolen_value</th>\n",
       "      <th>recovered_flag</th>\n",
       "      <th>agency_type_name_City</th>\n",
       "      <th>agency_type_name_County</th>\n",
       "      <th>agency_type_name_State Police</th>\n",
       "      <th>agency_type_name_Tribal/Federal/Other</th>\n",
       "      <th>agency_type_name_University or College</th>\n",
       "      <th>...</th>\n",
       "      <th>weapon_code_20</th>\n",
       "      <th>weapon_code_30</th>\n",
       "      <th>weapon_code_35</th>\n",
       "      <th>weapon_code_40</th>\n",
       "      <th>weapon_code_50</th>\n",
       "      <th>weapon_code_70</th>\n",
       "      <th>weapon_code_85</th>\n",
       "      <th>weapon_code_90</th>\n",
       "      <th>weapon_code_95</th>\n",
       "      <th>weapon_code_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122951</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122952</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122953</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>78</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122954</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122955</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>77</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121714 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        offender_age  location_code  prop_desc_code  stolen_value  \\\n",
       "0                0.0             25              20         375.0   \n",
       "1                0.0             20              77           1.0   \n",
       "2                0.0             20              65           0.0   \n",
       "3                0.0             20              13         320.0   \n",
       "4                0.0             20              77           1.0   \n",
       "...              ...            ...             ...           ...   \n",
       "122951           0.0             25              37       10000.0   \n",
       "122952           0.0             25              36          35.0   \n",
       "122953           0.0             18              78       20000.0   \n",
       "122954           0.0              7               2          32.0   \n",
       "122955           0.0             18              77       27000.0   \n",
       "\n",
       "        recovered_flag  agency_type_name_City  agency_type_name_County  \\\n",
       "0                    0                    0.0                      1.0   \n",
       "1                    0                    0.0                      1.0   \n",
       "2                    0                    0.0                      1.0   \n",
       "3                    0                    0.0                      1.0   \n",
       "4                    0                    0.0                      1.0   \n",
       "...                ...                    ...                      ...   \n",
       "122951               1                    0.0                      1.0   \n",
       "122952               0                    0.0                      1.0   \n",
       "122953               1                    0.0                      1.0   \n",
       "122954               0                    1.0                      0.0   \n",
       "122955               1                    0.0                      1.0   \n",
       "\n",
       "        agency_type_name_State Police  agency_type_name_Tribal/Federal/Other  \\\n",
       "0                                 0.0                                    0.0   \n",
       "1                                 0.0                                    0.0   \n",
       "2                                 0.0                                    0.0   \n",
       "3                                 0.0                                    0.0   \n",
       "4                                 0.0                                    0.0   \n",
       "...                               ...                                    ...   \n",
       "122951                            0.0                                    0.0   \n",
       "122952                            0.0                                    0.0   \n",
       "122953                            0.0                                    0.0   \n",
       "122954                            0.0                                    0.0   \n",
       "122955                            0.0                                    0.0   \n",
       "\n",
       "        agency_type_name_University or College  ...  weapon_code_20  \\\n",
       "0                                          0.0  ...             0.0   \n",
       "1                                          0.0  ...             0.0   \n",
       "2                                          0.0  ...             0.0   \n",
       "3                                          0.0  ...             0.0   \n",
       "4                                          0.0  ...             0.0   \n",
       "...                                        ...  ...             ...   \n",
       "122951                                     0.0  ...             0.0   \n",
       "122952                                     0.0  ...             0.0   \n",
       "122953                                     0.0  ...             0.0   \n",
       "122954                                     0.0  ...             0.0   \n",
       "122955                                     0.0  ...             0.0   \n",
       "\n",
       "        weapon_code_30  weapon_code_35  weapon_code_40  weapon_code_50  \\\n",
       "0                  0.0             0.0             0.0             0.0   \n",
       "1                  0.0             0.0             0.0             0.0   \n",
       "2                  0.0             0.0             0.0             0.0   \n",
       "3                  0.0             0.0             0.0             0.0   \n",
       "4                  0.0             0.0             0.0             0.0   \n",
       "...                ...             ...             ...             ...   \n",
       "122951             0.0             0.0             0.0             0.0   \n",
       "122952             0.0             0.0             0.0             0.0   \n",
       "122953             0.0             0.0             0.0             0.0   \n",
       "122954             0.0             0.0             0.0             0.0   \n",
       "122955             0.0             0.0             0.0             0.0   \n",
       "\n",
       "        weapon_code_70  weapon_code_85  weapon_code_90  weapon_code_95  \\\n",
       "0                  0.0             0.0             0.0             1.0   \n",
       "1                  0.0             0.0             0.0             1.0   \n",
       "2                  0.0             0.0             0.0             1.0   \n",
       "3                  0.0             0.0             0.0             1.0   \n",
       "4                  0.0             0.0             0.0             1.0   \n",
       "...                ...             ...             ...             ...   \n",
       "122951             0.0             0.0             0.0             1.0   \n",
       "122952             0.0             0.0             0.0             1.0   \n",
       "122953             0.0             0.0             0.0             1.0   \n",
       "122954             0.0             0.0             0.0             1.0   \n",
       "122955             0.0             0.0             0.0             1.0   \n",
       "\n",
       "        weapon_code_99  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "122951             0.0  \n",
       "122952             0.0  \n",
       "122953             0.0  \n",
       "122954             0.0  \n",
       "122955             0.0  \n",
       "\n",
       "[121714 rows x 122 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outliers in the cash value had been detected, lets filter those out?\n",
    "\n",
    "fbi_new = fbi_df2[fbi_df2[\"stolen_value\"] <100000]\n",
    "fbi_new\n",
    "#This took about 1,000 outliers out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aeb084a8-15ab-4415-bab8-2fabe6fb71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's do it all over again\n",
    "#with an additional set of bucketing done, it's time to go ahead and try some models\n",
    "#SPLIT THE DATA FOR TESTING AND TRAINING\n",
    "y = fbi_new[\"recovered_flag\"].values\n",
    "X = fbi_new.drop(labels =\"recovered_flag\",axis =1).values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=78)\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef50f8dc-3dff-4993-a9e4-9ac2debe74a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 3)                 366       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 382\n",
      "Trainable params: 382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#try the balanced model again\n",
    "#time to define the first new model with our slightly modified data.\n",
    "#start with basic 3-3-1\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 3\n",
    "hidden_nodes_layer2 = 3\n",
    "\n",
    "nn7 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn7.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features,activation=\"relu\"))\n",
    "       \n",
    "# Second hidden layer\n",
    "nn7.add(tf.keras.layers.Dense(units=hidden_nodes_layer2 ,activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn7.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "def2e2a6-c6c0-4cac-a989-bdf2262e661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn7.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc3f4d1d-0a4f-4878-a6c1-538b90335464",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2853/2853 [==============================] - 4s 1ms/step - loss: 4.1736 - accuracy: 0.8383\n",
      "Epoch 2/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3688 - accuracy: 0.8612\n",
      "Epoch 3/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3564 - accuracy: 0.8615\n",
      "Epoch 4/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3539 - accuracy: 0.8617\n",
      "Epoch 5/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3514 - accuracy: 0.8621\n",
      "Epoch 6/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3533 - accuracy: 0.8620\n",
      "Epoch 7/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3496 - accuracy: 0.8621\n",
      "Epoch 8/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3491 - accuracy: 0.8622\n",
      "Epoch 9/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3527 - accuracy: 0.8622\n",
      "Epoch 10/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3467 - accuracy: 0.8623\n",
      "Epoch 11/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3474 - accuracy: 0.8623\n",
      "Epoch 12/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3441 - accuracy: 0.8622\n",
      "Epoch 13/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3463 - accuracy: 0.8622\n",
      "Epoch 14/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3440 - accuracy: 0.8622\n",
      "Epoch 15/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3424 - accuracy: 0.8621\n",
      "Epoch 16/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3419 - accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3445 - accuracy: 0.8621\n",
      "Epoch 18/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3421 - accuracy: 0.8621\n",
      "Epoch 19/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3410 - accuracy: 0.8620\n",
      "Epoch 20/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3430 - accuracy: 0.8620\n",
      "Epoch 21/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3418 - accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3416 - accuracy: 0.8620\n",
      "Epoch 23/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3412 - accuracy: 0.8619\n",
      "Epoch 24/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3410 - accuracy: 0.8620\n",
      "Epoch 25/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3421 - accuracy: 0.8620\n",
      "Epoch 26/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3393 - accuracy: 0.8619\n",
      "Epoch 27/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3399 - accuracy: 0.8618\n",
      "Epoch 28/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3397 - accuracy: 0.8618\n",
      "Epoch 29/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3388 - accuracy: 0.8617\n",
      "Epoch 30/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3378 - accuracy: 0.8617\n",
      "Epoch 31/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3395 - accuracy: 0.8618\n",
      "Epoch 32/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3400 - accuracy: 0.8619\n",
      "Epoch 33/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3386 - accuracy: 0.8619\n",
      "Epoch 34/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3390 - accuracy: 0.8618\n",
      "Epoch 35/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3376 - accuracy: 0.8619\n",
      "Epoch 36/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3382 - accuracy: 0.8618\n",
      "Epoch 37/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3404 - accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3376 - accuracy: 0.8618\n",
      "Epoch 39/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3369 - accuracy: 0.8617\n",
      "Epoch 40/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3402 - accuracy: 0.8617\n",
      "Epoch 41/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3374 - accuracy: 0.8618\n",
      "Epoch 42/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3368 - accuracy: 0.8618\n",
      "Epoch 43/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3380 - accuracy: 0.8617\n",
      "Epoch 44/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3370 - accuracy: 0.8616\n",
      "Epoch 45/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3361 - accuracy: 0.8618\n",
      "Epoch 46/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3373 - accuracy: 0.8617\n",
      "Epoch 47/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3376 - accuracy: 0.8618\n",
      "Epoch 48/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3388 - accuracy: 0.8617\n",
      "Epoch 49/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3390 - accuracy: 0.8617\n",
      "Epoch 50/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3358 - accuracy: 0.8618\n",
      "Epoch 51/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3367 - accuracy: 0.8617\n",
      "Epoch 52/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3359 - accuracy: 0.8618\n",
      "Epoch 53/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3356 - accuracy: 0.8617\n",
      "Epoch 54/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3351 - accuracy: 0.8618\n",
      "Epoch 55/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3375 - accuracy: 0.8617\n",
      "Epoch 56/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3352 - accuracy: 0.8617\n",
      "Epoch 57/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3352 - accuracy: 0.8618\n",
      "Epoch 58/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3353 - accuracy: 0.8618\n",
      "Epoch 59/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3348 - accuracy: 0.8617\n",
      "Epoch 60/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3347 - accuracy: 0.8618\n",
      "Epoch 61/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3366 - accuracy: 0.8619\n",
      "Epoch 62/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3347 - accuracy: 0.8618\n",
      "Epoch 63/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3351 - accuracy: 0.8618\n",
      "Epoch 64/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3350 - accuracy: 0.8618\n",
      "Epoch 65/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3347 - accuracy: 0.8619\n",
      "Epoch 66/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3344 - accuracy: 0.8617\n",
      "Epoch 67/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3344 - accuracy: 0.8618\n",
      "Epoch 68/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3333 - accuracy: 0.8618\n",
      "Epoch 69/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3349 - accuracy: 0.8617\n",
      "Epoch 70/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3353 - accuracy: 0.8617\n",
      "Epoch 71/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3331 - accuracy: 0.8618\n",
      "Epoch 72/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3337 - accuracy: 0.8617\n",
      "Epoch 73/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3368 - accuracy: 0.8617\n",
      "Epoch 74/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3352 - accuracy: 0.8617\n",
      "Epoch 75/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3344 - accuracy: 0.8618\n",
      "Epoch 76/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8617\n",
      "Epoch 77/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3352 - accuracy: 0.8618\n",
      "Epoch 78/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3340 - accuracy: 0.8617\n",
      "Epoch 79/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3352 - accuracy: 0.8617\n",
      "Epoch 80/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3345 - accuracy: 0.8617\n",
      "Epoch 81/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3347 - accuracy: 0.8618\n",
      "Epoch 82/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3339 - accuracy: 0.8617\n",
      "Epoch 83/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3331 - accuracy: 0.8618\n",
      "Epoch 84/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3326 - accuracy: 0.8617\n",
      "Epoch 85/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3336 - accuracy: 0.8617\n",
      "Epoch 86/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3340 - accuracy: 0.8617\n",
      "Epoch 87/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3337 - accuracy: 0.8617\n",
      "Epoch 88/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3334 - accuracy: 0.8617\n",
      "Epoch 89/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3349 - accuracy: 0.8617\n",
      "Epoch 90/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3333 - accuracy: 0.8617\n",
      "Epoch 91/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3326 - accuracy: 0.8617\n",
      "Epoch 92/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3351 - accuracy: 0.8617\n",
      "Epoch 93/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3349 - accuracy: 0.8617\n",
      "Epoch 94/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3325 - accuracy: 0.8617\n",
      "Epoch 95/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3343 - accuracy: 0.8617\n",
      "Epoch 96/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3353 - accuracy: 0.8618\n",
      "Epoch 97/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3347 - accuracy: 0.8618\n",
      "Epoch 98/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3326 - accuracy: 0.8618\n",
      "Epoch 99/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3337 - accuracy: 0.8618\n",
      "Epoch 100/100\n",
      "2853/2853 [==============================] - 3s 1ms/step - loss: 0.3323 - accuracy: 0.8618\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn7.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9bf65c41-7af0-4cbb-9f31-5666fbb9e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951/951 - 1s - loss: 0.4653 - accuracy: 0.7678 - 845ms/epoch - 888us/step\n",
      "Loss: 0.46533429622650146, Accuracy: 0.7678201794624329\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn7.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "#not good but it's better than had been, not as good as best model though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0964396-fe39-459d-b639-51281b1b1f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_type_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>region_name</th>\n",
       "      <th>population_group_code</th>\n",
       "      <th>offense_code</th>\n",
       "      <th>offender_race</th>\n",
       "      <th>offender_sex</th>\n",
       "      <th>victim_type_code</th>\n",
       "      <th>location_code</th>\n",
       "      <th>weapon_code</th>\n",
       "      <th>prop_desc_code</th>\n",
       "      <th>stolen_value</th>\n",
       "      <th>recovered_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>County</td>\n",
       "      <td>Texas</td>\n",
       "      <td>South</td>\n",
       "      <td>8B</td>\n",
       "      <td>26B</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>20</td>\n",
       "      <td>375.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23H</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>I</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122951</th>\n",
       "      <td>County</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122952</th>\n",
       "      <td>County</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>36</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122953</th>\n",
       "      <td>County</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>240</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>78</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122954</th>\n",
       "      <td>City</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>South</td>\n",
       "      <td>1B</td>\n",
       "      <td>23F</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122955</th>\n",
       "      <td>County</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>South</td>\n",
       "      <td>9A</td>\n",
       "      <td>240</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122956 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       agency_type_name      state_name region_name population_group_code  \\\n",
       "0                County           Texas       South                    8B   \n",
       "1                County         Alabama       South                    9A   \n",
       "2                County         Alabama       South                    9A   \n",
       "3                County         Alabama       South                    9A   \n",
       "4                County         Alabama       South                    9A   \n",
       "...                 ...             ...         ...                   ...   \n",
       "122951           County         Florida       South                    9A   \n",
       "122952           County         Florida       South                    9A   \n",
       "122953           County  South Carolina       South                    9A   \n",
       "122954             City       Tennessee       South                    1B   \n",
       "122955           County  South Carolina       South                    9A   \n",
       "\n",
       "       offense_code offender_race offender_sex victim_type_code  \\\n",
       "0               26B       Unknown            U                I   \n",
       "1               23H       Unknown            U                I   \n",
       "2               23H       Unknown            U                I   \n",
       "3               23H       Unknown            U                I   \n",
       "4               23F       Unknown            U                I   \n",
       "...             ...           ...          ...              ...   \n",
       "122951          23F       Unknown            U                B   \n",
       "122952          23F       Unknown            U                B   \n",
       "122953          240       Unknown            U                B   \n",
       "122954          23F       Unknown            U                B   \n",
       "122955          240       Unknown            U                B   \n",
       "\n",
       "        location_code weapon_code  prop_desc_code  stolen_value  \\\n",
       "0                  25          95              20         375.0   \n",
       "1                  20          95              77           1.0   \n",
       "2                  20          95              65           0.0   \n",
       "3                  20          95              13         320.0   \n",
       "4                  20          95              77           1.0   \n",
       "...               ...         ...             ...           ...   \n",
       "122951             25          95              37       10000.0   \n",
       "122952             25          95              36          35.0   \n",
       "122953             18          95              78       20000.0   \n",
       "122954              7          95               2          32.0   \n",
       "122955             18          95              77       27000.0   \n",
       "\n",
       "        recovered_flag  \n",
       "0                False  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "...                ...  \n",
       "122951            True  \n",
       "122952           False  \n",
       "122953            True  \n",
       "122954           False  \n",
       "122955            True  \n",
       "\n",
       "[122956 rows x 13 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try modifying this with the additional dropped data of our earlier better dataset, and then add try the best model again on that\n",
    "to_drop = [\"pub_agency_name\",\"division_name\", \"county_name\",\"offender_age\",\"offender_ethnicity\",\"Unnamed: 0\"]\n",
    "fbi_last = fbi_df1.drop(labels=to_drop, axis=1)\n",
    "fbi_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "54911e30-d782-4f10-b167-f3d119843d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "North Carolina          26784\n",
       "Ohio                    11927\n",
       "Massachusetts           10788\n",
       "Texas                   10233\n",
       "Georgia                  9850\n",
       "Tennessee                4891\n",
       "South Carolina           4596\n",
       "Virginia                 4468\n",
       "Michigan                 3772\n",
       "Alabama                  3393\n",
       "West Virginia            3383\n",
       "Maryland                 2419\n",
       "Nevada                   2308\n",
       "Pennsylvania             2263\n",
       "Missouri                 2145\n",
       "Indiana                  1581\n",
       "New Mexico               1518\n",
       "Oregon                   1437\n",
       "California               1375\n",
       "Washington               1372\n",
       "Colorado                 1367\n",
       "New Jersey               1359\n",
       "Illinois                 1350\n",
       "Arkansas                 1292\n",
       "Florida                  1283\n",
       "Mississippi              1232\n",
       "Kentucky                  804\n",
       "Iowa                      531\n",
       "Connecticut               388\n",
       "Nebraska                  343\n",
       "Rhode Island              305\n",
       "Wisconsin                 283\n",
       "Arizona                   278\n",
       "Montana                   216\n",
       "Idaho                     210\n",
       "Delaware                  191\n",
       "North Dakota              183\n",
       "South Dakota              170\n",
       "Utah                      138\n",
       "Minnesota                 126\n",
       "New York                  126\n",
       "New Hampshire             100\n",
       "Alaska                     43\n",
       "Maine                      40\n",
       "Vermont                    39\n",
       "Oklahoma                   30\n",
       "Federal                    12\n",
       "Wyoming                     8\n",
       "District of Columbia        4\n",
       "Hawaii                      2\n",
       "Name: state_name, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-bucket and modify\n",
    "\n",
    "states_counts = fbi_last.state_name.value_counts()\n",
    "states_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11b8b762-b4b6-4bd7-90ce-1530e4c4ec90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8432\\95180875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Replace in DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfbi_last\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfbi_last\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Other_US_States/Territories\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5514\u001b[0m                     \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5515\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5516\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5517\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5518\u001b[0m                     \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3600\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3601\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3602\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3603\u001b[0m         elif (\n\u001b[0;32m   3604\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3727\u001b[0m             \u001b[0mlen_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen_cols\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3729\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Columns must be same length as key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3731\u001b[0m             \u001b[1;31m# align right-hand-side columns if self.columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# cutting off at 1,000 and call it \"Other US States/Territories\"\n",
    "replacements = list(states_counts[states_counts < 1000].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for state in replacements:\n",
    "    fbi_last.state_name = fbi_last.replace(state,\"Other_US_States/Territories\")\n",
    "\n",
    "\n",
    "# Check to make sure data succesfully binned\n",
    "fbi_last.state_name.value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
